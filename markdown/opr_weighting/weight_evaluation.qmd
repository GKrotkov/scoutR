---
title: "OPR Weighting Evaluation"
format: html
---

Note: to run this file successfully, you should already have run `markdown/opr_weighting/weight_estimation.qmd` and `markdown/opr_weighting/hyperparameter_tuning.qmd`. 

```{r setup, message = FALSE, warning = FALSE}
library(devtools)
load_all()
rm(list = ls())
load("../../data/district_quals_09_24.rda") # from scripts/get_district_quals.R

# normalize match scores so we can do cross-week and cross-season comparisons
# this simplifies a lot of later code
matches <- lapply(
    matches, 
    function(match_df){
        scaled <- scale(c(match_df$red_score, match_df$blue_score))
        match_df$red_score <- scaled[1:nrow(match_df)]
        match_df$blue_score <- scaled[(nrow(match_df) + 1):length(scaled)]
        return(match_df)
    })

library(extrafont)
library(gt)
gos_blue <- "#337DFC"
gos_red <- "#F7041A"

gos_theme <- theme_bw() + 
    theme(text = element_text(family = "Futura"))

# from markdown/opr_weighting/weight_estimation.qmd
load("../../data/opr_weights.rda")
# from markdown/opr_weighting/hyperparameter_tuning.qmd
load("../../data/optimized_opr_weighting.rda")

weighted_fit <- function(match_df, w){
    return(
        fit_lineup_lm(
            match_df, 
            responses = list(
                red = match_df$red_score, blue = match_df$blue_score
            ), 
            w = w
        )
    )
}
```

# Test MSE

Reasons to reserve the last 3/12 matches instead of randomly selecting: 
- Casts the problem as a prediction, rather than inference, problem: we are interested in approximating a team's performance heading into the playoff rounds 
- Follows the sequential nature of the data 
- Treats every event in the same manner, while if we randomly picked there would be an interaction with the year effect which would be difficult to account for

```{r optimization-helpers}
# assume matches is a dataframe of matches with red_score and blue_score columns
# uses WLS for computational efficiency
# computes the ratio between the unweighted and weighted model test MSE
compute_mse_ratio <- function(matches, w){
    # reserve the last 3/12 matches for testing
    test <- weight_rows(matches, c(rep(0, 3), 1))
    train <- weight_rows(matches, c(rep(1, 3), 0))

    null_fit <- fit_lineup_lm(
        train, list(red = train$red_score, blue = train$blue_score)
    )

    weighted_fit <- fit_lineup_lm(
        train, list(red = train$red_score, blue = train$blue_score), w = w
    )

    test_design <- lineup_design_matrix(test)
    test_design$response <- c(test$blue_score, test$red_score)
    
    preds_null <- predict(null_fit, newdata = test_design)
    preds_weighted <- predict(weighted_fit, newdata = test_design)
    true_response <- c(test$blue_score, test$red_score)
    
    mse_null <- mean((preds_null - true_response) ^ 2)
    mse_weighted <- mean((preds_weighted - true_response) ^ 2)
    return(mse_null / mse_weighted)
}

# matches - list of dataframes, each with qual matches with >= 12 matches/team
# w - vector representing the weighting
# returns a vector of mean squared errors for each event in `matches`, where
# negative means that the weighted models performed better and positive means
# that the null models performed better.
test_weighting <- function(matches, w){
    # don't need to normalize weights anymore because the helper function does
    diffs <- sapply(
        matches, compute_mse_ratio, w = w
    )
    names(diffs) <- names(matches)
    return(diffs)
}
```

Use the bootstrap to approximate a confidence interval for the ratio (raw OPR MSE / weighted OPR MSE)

```{r test-mse-bootstrap}
mse_ratios <- test_weighting(matches, w_stepwise)

viz <- data.frame(mse_ratio = mse_ratios, 
                  year = as.factor(substr(names(mse_ratios), 1, 4)))

# generate B bootstrap samples and compute the mean MSE ratio for each sample.
B <- 1000
bstrap_ratios <- rep(NA, B)
for (i in 1:B){
    bstrap_sample <- sample(mse_ratios, length(mse_ratios), replace = TRUE)
    bstrap_ratios[i] <- mean(bstrap_sample)
}
# Now we can take the 2.5th percentile value and the 97.5th percentile value 
# from those ratios to define the lower and upper bound for a 95% CI
bstrap_ratios <- sort(bstrap_ratios)
# lower bound for mean test MSE ratio
bstrap_lower <- bstrap_ratios[floor(B * 0.025)]
# upper bound for mean test MSE ratio
bstrap_upper <- bstrap_ratios[ceiling(B * 0.975)]
```

```{r test-mse-visualization}
ggplot(viz, aes(x = mse_ratio)) + 
    geom_histogram(fill = gos_blue, color = "black", 
                   bins = ceiling(sqrt(nrow(viz)))) + 
    geom_vline(aes(xintercept = mean(mse_ratio)), color = gos_red) + 
    geom_vline(aes(xintercept = bstrap_lower), color = gos_red, lty = 3) + 
    geom_vline(aes(xintercept = bstrap_upper), color = gos_red, lty = 3) + 
    annotate("label", x = mean(mse_ratios), y = 15, 
             label = paste0("Mean: ", round(mean(mse_ratios), 3), "\n", 
                            "95% CI: (", round(bstrap_lower, 3), ", ", 
                            round(bstrap_upper, 3), ")")) +
    labs(title = "OPR Weighting Test MSE Ratio (Stepwise Optimized)", 
         subtitle = "District Event Qualifications, 2009 - 2024", 
         x = "Event-Normalized MSE Ratio (null:weighted)", 
         y = "# Events") +
    gos_theme

ggplot(viz, aes(x = mse_ratio)) + 
    geom_density(alpha = 0.2, fill = gos_blue) + 
    facet_wrap(~year) +
    labs(title = "OPR Weighting Test MSE Ratio", x = "Test MSE Ratio", 
         y = "Density") + 
    gos_theme

viz <- viz %>%
    group_by(year) %>%
    summarize(events = n(), 
              mean_diff = mean(mse_ratio), 
              median_diff = median(mse_ratio))

colnames(viz) <- c(
    "Year", "# Events", "Mean MSE Ratio", "Median MSE Ratio"
)

gt(viz) %>%
    tab_header(
        title = "Yearly MSE ratios raw:weighted OPR"
    ) %>%
    tab_options(
        column_labels.background.color = gos_blue
    ) %>%
    tab_style(
        cell_borders(color = gos_blue), 
        cells_body()
    ) %>%
    opt_table_font(
        font = "Futura"
    )
```

# In-Sample MSE

```{r in-sample-mse}
compute_in_sample_mse <- function(matches, w){
    fits <- lapply(matches, weighted_fit, w = w)
    mses <- sapply(
        fits, function(fit){
           return(mean(residuals(fit) ^ 2))
        })
    return(mses)
}

stepwise_weighted_mse <- compute_in_sample_mse(matches, w_stepwise)
fitvar_weighted_mse <- compute_in_sample_mse(matches, w_bin_fitted_vars)
residvar_weighted_mse <- compute_in_sample_mse(matches, w_bin_resid_vars)
raw_mse <- compute_in_sample_mse(matches, 1)

viz <- data.frame(stepwise_ratio = raw_mse / stepwise_weighted_mse, 
                  fitvar_ratio = raw_mse / fitvar_weighted_mse, 
                  residvar_ratio = raw_mse / residvar_weighted_mse,
                  year = as.factor(substr(names(raw_mse), 1, 4)))

ggplot(viz, aes(x = stepwise_ratio)) + 
    geom_histogram(fill = gos_blue, color = "black", 
                   bins = ceiling(sqrt(nrow(viz)))) + 
    geom_vline(aes(xintercept = mean(stepwise_ratio)), color = gos_red) + 
    annotate("label", x = mean(viz$stepwise_ratio), y = 15, 
             label = paste0("Mean: ", round(mean(viz$stepwise_ratio), 6))) +
    labs(title = "In-Sample MSE Ratio (raw / weighted by stepwise optimization)", 
         subtitle = "District Event Qualifications, 2009 - 2024", 
         x = "Event-Normalized Mean Squared Error Difference (Std Devs)", 
         y = "# Events") +
    gos_theme

ggplot(viz, aes(x = fitvar_ratio)) + 
    geom_density(alpha = 0.2, fill = gos_blue) + 
    facet_wrap(~year) +
    labs(title = "OPR Weighting MSE Ratio", x = "MSE Ratio", 
         y = "Density") + 
    gos_theme

viz <- viz %>%
    group_by(year) %>%
    summarize(events = n(), 
              mean_diff = mean(fitvar_ratio), 
              median_diff = median(fitvar_ratio))

colnames(viz) <- c(
    "Year", "# Events", "Mean MSE Ratio", "Median MSE Ratio"
)

gt(viz) %>%
    tab_header(
        title = "Yearly MSE ratios between null and weighted OPR"
    ) %>%
    tab_options(
        column_labels.background.color = gos_blue
    ) %>%
    tab_style(
        cell_borders(color = gos_blue), 
        cells_body()
    ) %>%
    opt_table_font(
        font = "Futura"
    )
```

# LOOCV

Advantages of LOOCV: 
- Retains more of the training test so the weighting makes more sense
- Unbiased estimator of prediction risk, low variance because of the averaging over the entire hat matrix.
- Shortcut formula can make it computationally efficient
    - Makes weight optimization over a grid possible

```{r loocv-compute}
# this uses the "shortcut" formula for LOOCV
# see formula 5.2 in ISLR by James, Witten, Hastie, and Tibshirani (v2), pg 202
LOOCV <- function(fit){
    mean(((fit$model$response - predict(fit))/(1 - boot::glm.diag(fit)$h))^2)
}

linear_weight_fits <- lapply(matches, weighted_fit, w = w_linear)
bin_weight_fits <- lapply(matches, weighted_fit, w = w_bin_resid_vars)
fitted_var_weight_fits <- lapply(matches, weighted_fit, w = w_bin_fitted_vars)
stepwise_fits <- lapply(matches, weighted_fit, w = w_stepwise)
raw_fits <- lapply(matches, weighted_fit, w = 1)

linear_weight_loocvs <- sapply(linear_weight_fits, LOOCV)
resid_weight_loocvs <- sapply(bin_weight_fits, LOOCV)
fitted_weight_loocvs <- sapply(fitted_var_weight_fits, LOOCV)
stepwise_loocvs <- sapply(stepwise_fits, LOOCV)
raw_loocvs <- sapply(raw_fits, LOOCV)
```

Use the bootstrap to approximate the confidence interval on the ratio of LOOCV 

```{r loocv-bootstrap}
viz <- data.frame(linear_loocv_ratio = raw_loocvs / linear_weight_loocvs, 
                  resid_loocv_ratio = raw_loocvs / resid_weight_loocvs,
                  fitted_loocv_ratio = raw_loocvs / fitted_weight_loocvs,
                  stepwise_loocv_ratio = raw_loocvs / stepwise_loocvs,
                  year = as.factor(substr(names(raw_loocvs), 1, 4)))

# generate B bootstrap samples and compute the mean MSE ratio for each sample.
B <- 1000
stepwise_bstrap_ratios <- rep(NA, B)
binned_bstrap_ratios <- rep(NA, B)
for (i in 1:B){
    bstrap_sample <- sample(viz$stepwise_loocv_ratio, nrow(viz), replace = TRUE)
    stepwise_bstrap_ratios[i] <- mean(bstrap_sample)
    bstrap_sample <- sample(viz$resid_loocv_ratio, nrow(viz), replace = TRUE)
    binned_bstrap_ratios[i] <- mean(bstrap_sample)
}
# Now we can take the 2.5th percentile value and the 97.5th percentile value 
# from those ratios to define the lower and upper bound for a 95% CI
stepwise_bstrap_ratios <- sort(stepwise_bstrap_ratios)
binned_bstrap_ratios <- sort(binned_bstrap_ratios)
# lower bound for mean LOOCV ratio
stepwise_bstrap_lower <- stepwise_bstrap_ratios[floor(B * 0.025)]
binned_bstrap_lower <- binned_bstrap_ratios[floor(B * 0.025)]
# upper bound for mean LOOCV ratio
stepwise_bstrap_upper <- stepwise_bstrap_ratios[ceiling(B * 0.975)]
binned_bstrap_upper <- binned_bstrap_ratios[ceiling(B * 0.975)]
```

```{r loocv-viz}
ggplot(viz, aes(x = stepwise_loocv_ratio)) + 
    geom_histogram(fill = gos_blue, color = "black", 
                   bins = ceiling(sqrt(nrow(viz)))) + 
    geom_vline(aes(xintercept = mean(stepwise_loocv_ratio)), color = gos_red) + 
    geom_vline(aes(xintercept = stepwise_bstrap_lower), 
               color = gos_red, lty = 3) + 
    geom_vline(aes(xintercept = stepwise_bstrap_upper), 
               color = gos_red, lty = 3) + 
    annotate("label", x = mean(viz$stepwise_loocv_ratio), y = 15, 
             label = paste0("Mean: ", 
                            round(mean(viz$stepwise_loocv_ratio), 3), "\n", 
                            "95% CI: (", round(stepwise_bstrap_lower, 3), ", ", 
                            round(stepwise_bstrap_upper, 3), ")")) +
    labs(title = "OPR Weighting LOOCV Ratio (Stepwise Optimized)", 
         subtitle = "District Event Qualifications, 2009 - 2024", 
         x = "Event-Normalized LOOCV Error Ratio (raw:weighted)", 
         y = "# Events") +
    gos_theme

ggplot(viz, aes(x = resid_loocv_ratio)) + 
    geom_histogram(fill = gos_blue, color = "black", 
                   bins = ceiling(sqrt(nrow(viz)))) + 
    geom_vline(aes(xintercept = mean(resid_loocv_ratio)), color = gos_red) + 
    geom_vline(aes(xintercept = binned_bstrap_lower), 
               color = gos_red, lty = 3) + 
    geom_vline(aes(xintercept = binned_bstrap_upper), 
               color = gos_red, lty = 3) + 
    annotate("label", x = mean(viz$resid_loocv_ratio), y = 15, 
             label = paste0("Mean: ", 
                            round(mean(viz$resid_loocv_ratio), 3), "\n", 
                            "95% CI: (", round(binned_bstrap_lower, 3), ", ", 
                            round(binned_bstrap_upper, 3), ")")) +
    labs(title = "OPR Weighting LOOCV Ratio (Residual Binning)", 
         subtitle = "District Event Qualifications, 2009 - 2024", 
         x = "Event-Normalized LOOCV Error Ratio (raw:weighted)", 
         y = "# Events") +
    gos_theme

ggplot(viz, aes(x = stepwise_loocv_ratio)) + 
    geom_density(alpha = 0.2, fill = gos_blue) + 
    facet_wrap(~year) +
    labs(title = "OPR Weighting LOOCV Ratio", x = "LOOCV Difference", 
         y = "Density") + 
    gos_theme

viz <- viz %>%
    group_by(year) %>%
    summarize(events = n(), 
              linear_mean_ratio = mean(linear_loocv_ratio), 
              bin_mean_ratio = mean(resid_loocv_ratio), 
              stepwise_mean_ratio = mean(stepwise_loocv_ratio))

colnames(viz) <- c(
    "Year", "# Events", "Linear", "Binned", "Stepwise"
)

viz$Year <- as.numeric(as.character(viz$Year))
viz <- round(viz, digits = 4)
maxes <- pmax(viz$Linear, viz$Binned, viz$Stepwise)

gt(viz) %>%
    tab_header(
        title = "Mean LOOCV Ratios", 
        subtitle = "unweighted:weighted"
    ) %>%
    tab_options(
        column_labels.background.color = gos_blue
    ) %>%
    tab_style(
        style = cell_text(weight = "bold"), 
        locations = cells_body(columns = "Linear", 
                               rows = which(viz$Linear == maxes))
    ) %>%
    tab_style(
        style = cell_text(weight = "bold"), 
        locations = cells_body(columns = "Binned", 
                               rows = which(viz$Binned == maxes))
    ) %>%
    tab_style(
        style = cell_text(weight = "bold"), 
        locations = cells_body(columns = "Stepwise", 
                               rows = which(viz$Stepwise == maxes))
    ) %>%
    tab_style(
        cell_borders(color = gos_blue), 
        cells_body()
    ) %>%
    opt_table_font(
        font = "Futura"
    ) %>%
    tab_footnote(
        footnote = "Higher values indicate the weighting is performing better", 
        locations = cells_title("subtitle")
    )

viz$stepwise_mean_pct_improvement <- (viz$`Stepwise` - 1)
viz$binned_mean_pct_improvement <- (viz$Binned - 1)

ggplot(viz, aes(x = as.character(Year), y = stepwise_mean_pct_improvement)) + 
    geom_point(aes(size = `# Events`), col = gos_red) + 
    geom_hline(linetype = "dotted", linewidth = 1.25, col = gos_blue, 
               yintercept = mean(viz$stepwise_mean_pct_improvement)) + 
    geom_hline(yintercept = 0) +
    scale_y_continuous(labels = scales::percent) +
    labs(title = "Weighting Percent Improvement by Year", 
         subtitle = "By Mean LOOCV (stepwise optimized)", 
         x = "Year", y = "Mean LOOCV Percent Improvement") + 
    gos_theme

ggplot(viz, aes(x = as.character(Year), y = binned_mean_pct_improvement)) + 
    geom_point(aes(size = `# Events`), col = gos_red) + 
    geom_hline(linetype = "dotted", linewidth = 1.25, col = gos_blue, 
               yintercept = mean(viz$binned_mean_pct_improvement)) + 
    geom_hline(yintercept = 0) +
    scale_y_continuous(labels = scales::percent) +
    labs(title = "Weighting Percent Improvement by Year", 
         subtitle = "By Mean LOOCV (residual binning)", 
         x = "Year", y = "Mean LOOCV Percent Improvement") + 
    gos_theme
```

How much better are the stepwise optimized LOOCVs than the residual binning loocvs? (As a ratio)

```{r}
mean(stepwise_loocvs - raw_loocvs) / 
    mean(resid_weight_loocvs - raw_loocvs)
```

How many events saw improvement in the OPR fit from weighting?

```{r}
cat(round(sum((raw_loocvs / stepwise_loocvs) > 1) / length(raw_loocvs), 4) * 
        100, 
    "% of events saw improvement using the stepwise-optimzed weights", "\n")

cat(round(sum((raw_loocvs / resid_weight_loocvs) > 1) / length(raw_loocvs), 4) * 
        100, 
    "% of events saw improvement using the residual bin variance weights", "\n")

```

**Takeaway**: The stepwise-optimized weights are very, very good for years that are "normal" for OPR, while the residual bin variance weights are more conservative and flexible for years that do not satisfy the OPR assumptions very well (example: 2014, 2018)

What percent better are the weighted values on average?

```{r}
mean(((raw_loocvs / resid_weight_loocvs) - 1) * 100)
```
