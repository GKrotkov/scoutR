---
title: "opr_weight_optimization"
format: html
---

# Residuals against Match Percentile

It is difficult to optimize the weights because we are optimizing over an uncountably infinite grid. So we are interested in directly estimating the weights rather than numerically optimizing them.

Note that we standardize match scores on a per-event basis so we can make cross-event comparisons; so units are in standard deviations.

```{r setup, message = FALSE, warning = FALSE}
library(devtools)
load_all()
rm(list = ls())
load("../data/district_quals_09_24.rda")

# normalize match scores so we can do cross-week and cross-season comparisons
# this simplifies a lot of later code
matches <- lapply(
    matches, 
    function(match_df){
        scaled <- scale(c(match_df$red_score, match_df$blue_score))
        match_df$red_score <- scaled[1:nrow(match_df)]
        match_df$blue_score <- scaled[(nrow(match_df) + 1):length(scaled)]
        return(match_df)
    })

library(extrafont)
library(gt)
gos_blue <- "#337DFC"
gos_red <- "#F7041A"

gos_theme <- theme_bw() + 
    theme(text = element_text(family = "Futura"))
```

To estimate the weighting, we will fit a regular unweighted regression for each event and investigate the relationship between the residuals and the match number. To make comparison possible between events with different numbers of matches, we need to convert each match to a proportion of the progress through the tournament that the match took place at.

```{r}
fit_opr <- function(match_df){
    return(
        fit_lineup_lm(
            match_df, responses = list(
                red = match_df$red_score, blue = match_df$blue_score)
        )
    )
}

normalize_match_number <- function(opr_residual){
    # we know we can divide the length by 2 because there are 2 alliances/match
    alliance_corrected <- ((1:length(opr_residual) - 1) %% 
                               (length(opr_residual) / 2)) + 1
    return((alliance_corrected / length(opr_residual)) * 2)
}

fits <- lapply(matches, fit_opr)

residuals <- lapply(fits, function(fit){return(residuals(fit))})

# applies normalization on a per-event basis, so it respects year and week
# point variation
normalized_resids <- lapply(residuals, function(residuals){
    return(scale(residuals, center = FALSE))
})

viz <- data.frame(
    resids = unlist(residuals, use.names = FALSE),
    sq_resids = unlist(residuals, use.names = FALSE) ^ 2,
    match_percentile = unlist(lapply(residuals, normalize_match_number), 
                              use.names = FALSE)
)

sq_resid_fit <- lm(sq_resids ~ match_percentile, data = viz)

ggplot(viz, aes(x = match_percentile, y = sq_resids)) + 
    geom_point(col = gos_red, alpha = 0.2) + 
    geom_smooth(method = "lm", formula = y ~ x, col = "black") +
    annotate("label", 
             x = mean(viz$match_percentile), 
             y = mean(viz$sq_resids), 
             label = paste0(
                 "Slope: ", round(coefficients(sq_resid_fit)[2], 3))
             ) + 
    labs(title = "SLR residuals slightly decrease as the tournament proceeds", 
         x = "Qual Match Percentile", y = "Squared Residual") + 
    theme(text = element_text(family = "Futura"), 
          panel.background = element_rect(fill = "#FFFFFF", color = "#FFFFFF", 
                                          linewidth = 0.5, linetype = "solid"), 
          panel.grid.major = element_line(linewidth = 0.5, linetype = "solid", 
                                          color = gos_blue), 
          panel.grid.minor = element_line(linewidth = 0.25, linetype = "solid", 
                                          color = gos_blue))
```

# Residual Slope Weight Estimation

This estimator did not turn out well - actively worse than unweighteds

```{r, include = FALSE}
estimate_weights <- function(event_matches){
    fit <- fit_lineup_lm(
        event_matches, 
        list(red = event_matches$red_score, blue = event_matches$blue_score)
    )
    
    # sort residuals to be in match order
    resid <- c(rbind(
        residuals(fit)[1:nrow(event_matches)], 
        residuals(fit)[(nrow(event_matches) + 1):(2 * nrow(event_matches))]
    ))
    
    # repeat 1:nrow(matches) twice each for the two alliances in each match
    resid_fit <- lm(residuals(fit) ~ rep(1:nrow(event_matches), each = 2))
    # linear prediction fit for the weights
    w <- coefficients(resid_fit)[1] + 
        (coefficients(resid_fit)[2] * 1:nrow(event_matches))
    
    # normalize to ensure nonnegativity
    w <- (w - min(w)) / (max(w) - min(w))
    return(w)
}

rm(estimate_weights)
```

# Bin Variance Weight Estimates

```{r}
n_bins <- 6
cuts <- cut(viz$match_percentile, breaks = n_bins)
labs <- levels(cuts)

bin_vars <- rep(0, length(unique(cuts)))
# use standardized residuals to account for year and event week
for (i in 1:length(unique(cuts))){
    bin_vars[i] <- var(unlist(normalized_resids)[cuts == levels(cuts)[i]])
}

plot(x = 1:length(bin_vars), y = bin_vars, 
     xlab = "Bin Number", ylab = "Normalized Residual Variance", 
     main = "Residual Variance by Binned Tournament Progress")
```

Looking at the plot with varying numbers of bins, we'll model the variance in the residuals as two lines, one for the left-hand half of the data and one for the right-hand half of the data. We'll do two regressions to model this, one for match percentiles less than 0.5 and one for match percentiles greater than or equal to 0.5

```{r}
idx <- 1:(floor(length(bin_vars) / 2))
first_half_fit <- lm(bin_vars[idx] ~ idx)
idx <- (ceiling(length(bin_vars) / 2)):length(bin_vars)
second_half_fit <- lm(bin_vars[idx] ~ idx)

plot(x = 1:length(bin_vars), y = bin_vars, 
     xlab = "Bin Number", ylab = "Normalized Residual Variance", 
     main = "Two lines approximate the variance relationship")
abline(first_half_fit, col = gos_blue)
abline(second_half_fit, col = gos_red)
```

Now we need to write the variances in terms of the slopes, and then turn the variances into weights by inverting them.

```{r}
weights_from_lines <- function(intercept_1, intercept_2, n_bins, slope_1, slope_2){
    first_half <- rep(intercept_1, floor(n_bins / 2))
    first_half <- first_half + (slope_1 * (1:length(first_half) - 1))
    second_half <- rep(intercept_2 + (slope_2 * ((floor(n_bins / 2) + 1))), 
                       ceiling(n_bins / 2))
    second_half <- second_half + (slope_2 * (1:length(second_half) - 1))
    result <- 1 / c(first_half, second_half)
    names(result) <- NULL
    return(result)
}

w <- weights_from_lines(
    coefficients(first_half_fit)[1], coefficients(second_half_fit)[1], n_bins,
    coefficients(first_half_fit)[2], coefficients(second_half_fit)[2]
)
```

(We also tested the linear approximation weights against just using `1/bin_vars`, which performed worse by test MSE)

# Test MSE

Reasons to reserve the last 3/12 matches instead of randomly selecting: 
- Casts the problem as a prediction, rather than inference, problem: we are interested in approximating a team's performance heading into the playoff rounds 
- Follows the sequential nature of the data 
- Treats every event in the same manner, while if we randomly picked there would be an interaction with the year effect which would be difficult to account for

```{r optimization-helpers}
# redefine compute_mse_diff to use WLS
# assume matches is a dataframe of matches with red_score and blue_score columns
compute_mse_diff <- function(matches, w){
    # reserve the last 3/12 matches for testing
    test <- weight_rows(matches, c(rep(0, 3), 1))
    train <- weight_rows(matches, c(rep(1, 3), 0))

    null_fit <- fit_lineup_lm(
        train, list(red = train$red_score, blue = train$blue_score)
    )

    weighted_fit <- fit_lineup_lm(
        train, list(red = train$red_score, blue = train$blue_score), w = w
    )

    test_design <- lineup_design_matrix(test)
    test_design$response <- c(test$blue_score, test$red_score)
    
    preds_null <- predict(null_fit, newdata = test_design)
    preds_weighted <- predict(weighted_fit, newdata = test_design)
    true_response <- c(test$blue_score, test$red_score)
    
    mse_null <- mean((preds_null - true_response) ^ 2)
    mse_weighted <- mean((preds_weighted - true_response) ^ 2)
    return(mse_weighted - mse_null)
}

# matches - list of dataframes, each with qual matches with >= 12 matches/team
# w - vector representing the weighting
# returns a vector of mean squared errors for each event in `matches`, where
# negative means that the weighted models performed better and positive means
# that the null models performed better.
test_weighting <- function(matches, w){
    # don't need to normalize weights anymore because the helper function does
    diffs <- sapply(
        matches, compute_mse_diff, w = w
    )
    names(diffs) <- names(matches)
    return(diffs)
}
```

```{r visualization}
mse_diffs <- test_weighting(matches, w)

viz <- data.frame(mse_diff = mse_diffs, 
                  year = as.factor(substr(names(mse_diffs), 1, 4)))

ggplot(viz, aes(x = mse_diff)) + 
    geom_histogram(fill = gos_blue, color = "black", 
                   bins = ceiling(sqrt(nrow(viz)))) + 
    geom_vline(aes(xintercept = mean(mse_diff)), color = gos_red) + 
    annotate("label", x = mean(mse_diffs), y = 15, 
             label = paste0("Mean: ", round(mean(mse_diffs), 3))) +
    labs(title = "Weighting Improves OPR Predictions", 
         subtitle = "District Event Qualifications, 2009 - 2024", 
         x = "Event-Normalized Mean Squared Error Difference (Std Devs)", 
         y = "# Events") +
    gos_theme

ggplot(viz, aes(x = mse_diff)) + 
    geom_density(alpha = 0.2, fill = gos_blue) + 
    facet_wrap(~year) +
    labs(title = "OPR Weighting MSE Difference", x = "MSE Difference", 
         y = "Density") + 
    gos_theme

viz <- viz %>%
    group_by(year) %>%
    summarize(events = n(), 
              mean_diff = mean(mse_diff), 
              median_diff = median(mse_diff))

colnames(viz) <- c(
    "Year", "# Events", "Mean MSE Difference", "Median MSE Difference"
)

gt(viz) %>%
    tab_header(
        title = "Yearly MSE differences between null and weighted OPR"
    ) %>%
    tab_options(
        column_labels.background.color = gos_blue
    ) %>%
    tab_style(
        cell_borders(color = gos_blue), 
        cells_body()
    ) %>%
    opt_table_font(
        font = "Futura"
    )
```

# In-Sample MSE

```{r}
weighted_fit <- function(match_df, w){
    return(
        fit_lineup_lm(
            match_df, 
            responses = list(
                red = match_df$red_score, blue = match_df$blue_score
            ), 
            w = w
        )
    )
}

compute_in_sample_mse <- function(matches, w){
    fits <- lapply(matches, weighted_fit, w = w)
    mses <- sapply(
        fits, function(fit){
           return(mean(residuals(fit) ^ 2))
        })
    return(mses)
}

weighted_mse <- compute_in_sample_mse(matches, w)
raw_mse <- compute_in_sample_mse(matches, 1)

viz <- data.frame(mse_diff = raw_mse - weighted_mse, 
                  year = as.factor(substr(names(weighted_mse), 1, 4)))

ggplot(viz, aes(x = mse_diff)) + 
    geom_histogram(fill = gos_blue, color = "black", 
                   bins = ceiling(sqrt(nrow(viz)))) + 
    geom_vline(aes(xintercept = mean(mse_diff)), color = gos_red) + 
    annotate("label", x = mean(viz$mse_diff), y = 15, 
             label = paste0("Mean: ", round(mean(viz$mse_diff), 6))) +
    labs(title = "Weighting Improves OPR Predictions", 
         subtitle = "District Event Qualifications, 2009 - 2024", 
         x = "Event-Normalized Mean Squared Error Difference (Std Devs)", 
         y = "# Events") +
    gos_theme

ggplot(viz, aes(x = mse_diff)) + 
    geom_density(alpha = 0.2, fill = gos_blue) + 
    facet_wrap(~year) +
    labs(title = "OPR Weighting MSE Difference", x = "MSE Difference", 
         y = "Density") + 
    gos_theme

viz <- viz %>%
    group_by(year) %>%
    summarize(events = n(), 
              mean_diff = mean(mse_diff), 
              median_diff = median(mse_diff))

colnames(viz) <- c(
    "Year", "# Events", "Mean MSE Difference", "Median MSE Difference"
)

gt(viz) %>%
    tab_header(
        title = "Yearly MSE differences between null and weighted OPR"
    ) %>%
    tab_options(
        column_labels.background.color = gos_blue
    ) %>%
    tab_style(
        cell_borders(color = gos_blue), 
        cells_body()
    ) %>%
    opt_table_font(
        font = "Futura"
    )
```

# LOOCV

Advantages of LOOCV: 
- Retains more of the training test so the weighting makes more sense
- Shortcut formula can make it computationally efficient
    - Makes weight optimization over a grid possible

```{r}
LOOCV <- function(fit){
    mean(((fit$model$response - predict(fit))/(1 - boot::glm.diag(fit)$h))^2)
}

weighted_fits <- lapply(matches, weighted_fit, w = w)
raw_fits <- lapply(matches, weighted_fit, w = 1)

weighted_loocvs <- sapply(weighted_fits, LOOCV)
raw_loocvs <- sapply(raw_fits, LOOCV)

viz <- data.frame(loocv_diff = weighted_loocvs - raw_loocvs, 
                  year = as.factor(substr(names(raw_loocvs), 1, 4)))

ggplot(viz, aes(x = loocv_diff)) + 
    geom_histogram(fill = gos_blue, color = "black", 
                   bins = ceiling(sqrt(nrow(viz)))) + 
    geom_vline(aes(xintercept = mean(loocv_diff)), color = gos_red) + 
    annotate("label", x = mean(viz$loocv_diff), y = 15, 
             label = paste0("Mean: ", round(mean(viz$loocv_diff), 3))) +
    labs(title = "Weighting Improves OPR Predictions", 
         subtitle = "District Event Qualifications, 2009 - 2024", 
         x = "Event-Normalized LOOCV Error Difference (Std Devs)", 
         y = "# Events") +
    gos_theme

ggplot(viz, aes(x = loocv_diff)) + 
    geom_density(alpha = 0.2, fill = gos_blue) + 
    facet_wrap(~year) +
    labs(title = "OPR Weighting LOOCV Difference", x = "LOOCV Difference", 
         y = "Density") + 
    gos_theme

viz <- viz %>%
    group_by(year) %>%
    summarize(events = n(), 
              mean_diff = mean(loocv_diff), 
              median_diff = median(loocv_diff))

colnames(viz) <- c(
    "Year", "# Events", "Mean LOOCV Difference", "Median LOOCV Difference"
)

gt(viz) %>%
    tab_header(
        title = "LOOCV differences between raw and weighted OPR"
    ) %>%
    tab_options(
        column_labels.background.color = gos_blue
    ) %>%
    tab_style(
        cell_borders(color = gos_blue), 
        cells_body()
    ) %>%
    opt_table_font(
        font = "Futura"
    )
```

